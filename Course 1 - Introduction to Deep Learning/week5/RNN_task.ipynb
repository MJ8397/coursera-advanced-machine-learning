{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "PD12XVOB1WzO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "SwyFEBcT2ehf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b204d31-ca80-45a1-e3f8-34b141d877a1"
      },
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()  # change to the week you're working on\n",
        "# note on week 2: select setup_week2_v2() if you've started the course after August 13, 2018,\n",
        "# otherwise call setup_week2()."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.1’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ExYSqYhe1WzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc397e53-b291-4c27-c6bb-b262e33898c0"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "weZQaRo91WzW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "id": "RZsCBuWe1WzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-GqRBji1WzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1f3bbe07-3b38-403e-ed5f-4e77fa8122b1"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQpsbZq61Wzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b1eb7e55-0d0e-4c05-f242-d82baee60e4e"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe9476ee438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xWKSGw-u1Wze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "id": "jjj7WtWK1Wzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f9b8a33-84af-40a0-a55c-f2b7b7a58e7a"
      },
      "cell_type": "code",
      "source": [
        "tokens = set(''.join(names))\n",
        "\n",
        "tokens = sorted(list(tokens))\n",
        "tokens.insert(0,'#') # to add pad token\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bFQ0jDIIxU-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "9c7580f9-e807-470e-d619-05b6cab3e029"
      },
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#',\n",
              " ' ',\n",
              " \"'\",\n",
              " '-',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "8HL-FPmM1Wzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "id": "8MSZjW_K1Wzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "token_to_id = {c: i for i, c in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d91tkNpi1Wzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LPqxooPH1Wzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5a23fb8d-3707-4841-b48d-dda476120dcc"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 1  4 31 30 36 30 34 41  0]\n",
            " [ 1 10 41 44 47 54  0  0  0]\n",
            " [ 1 19 47 38 48 48 38 34  0]\n",
            " [ 1 10 38 44 51 30 43 43 34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_H91B6Tz1Wzu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "id": "KuXER8ON1Wzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GpDNnq201Wzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71E2UOxF1Wz1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "id": "0tDTc5bR1Wz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], axis=1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCV7BU5z1Wz5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "id": "seJq9SYz1Wz6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGzynngS1Wz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "id": "62zfCgTb1Wz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TD7frcMh1W0A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "id": "QquVb0bQ1W0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*tf.log(tf.clip_by_value(predictions_matrix,1e-10,1.0)), reduction_indices=[1])) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbSetPZL1W0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "id": "p5HXxp0M1W0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "49c2de62-91b1-4cff-9589-74a6c7e7446a"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neiAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe93459aef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6IlVilKy1W0H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "id": "wDiFqMa21W0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWb2ihO11W0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ygP3e1G41W0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2f7b8581-806a-4da0-cbb8-1b29ce0a21cc"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Eatlh\n",
            " Ash\n",
            " erviny\n",
            " Dobie\n",
            " Aray\n",
            " Gonti\n",
            " Berned\n",
            " Shienell\n",
            " Marni\n",
            " Naulle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AUwe-rcL1W0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dc9bae1c-cfcf-4307-8704-099d3e8c24d0"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpy\n",
            " Trumppan\n",
            " Trumpina\n",
            " Trumpa\n",
            " Trumpon\n",
            " Trump\n",
            " Trumpa\n",
            " Trump\n",
            " Trump\n",
            " Trumpyna\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "myHl4Xu91W0W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "id": "cNTYrUl31W0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"5fQLlpN6Q3dScyrm\"\n",
        "COURSERA_EMAIL = \"xnone0104@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2E2MpwT1W0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "40b3c570-63b0-44d1-be66-b84baed9964e"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnBaniLw1W0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "id": "5o9hyQuK1W0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "id": "8ZP3ajdl1W0j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQhTMECG1W0n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "id": "VsnMwqYZ1W0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFVeawbD1W0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}